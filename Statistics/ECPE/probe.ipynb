{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n",
      "143\n",
      "223\n",
      "236\n",
      "430\n",
      "913\n",
      "999\n",
      "1340\n",
      "1513\n",
      "1517\n",
      "1519\n",
      "1557\n",
      "1645\n",
      "1670\n",
      "1738\n",
      "1755\n",
      "1760\n",
      "1806\n",
      "1853\n",
      "1939\n",
      "1940\n",
      "2011\n",
      "2053\n",
      "2088\n",
      "2100\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Define class\n",
    "class Statistics():\n",
    "    def __init__(self, key, emo_conn, cau_conn, typ, dis):\n",
    "        self.key = key\n",
    "        self.emo_conn = emo_conn\n",
    "        self.cau_conn = cau_conn\n",
    "        self.typ = typ\n",
    "        self.dis = dis\n",
    "        self.frequency = 0\n",
    "\n",
    "# Init param\n",
    "result = []  # Statistic result\n",
    "key = []  # Primary key for index\n",
    "conn_words = []  # Set connectives\n",
    "\n",
    "key.append('>2')\n",
    "new_situation = Statistics('>2', '', '', 0, '>2')\n",
    "result.append(new_situation)\n",
    "# conn_words_count = []  # Set connectives connt\n",
    "\n",
    "# Load cause connectives\n",
    "with open ('../../data/conn.txt', 'r', encoding='utf-8') as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        for word in line.split(','):\n",
    "            conn_words.append(word)\n",
    "        line = f.readline()\n",
    "\n",
    "with open ('../../data/all_data_pair_zh.txt', 'r', encoding='utf-8') as f:  # Encode by utf-8 for Chinese\n",
    "    sec = f.readline()  # Read section ID and length\n",
    "\n",
    "    # For each section\n",
    "    while sec:\n",
    "\n",
    "        # Get section length\n",
    "        num = sec.split(' ')\n",
    "        section = int(num[0])\n",
    "        length = int(num[1])\n",
    "        content = ['' for i in range(length)]\n",
    "        refined_content = ['' for i in range(length)]\n",
    "\n",
    "        pairs = f.readline().lstrip().rstrip()  # Get the index of pairs and delete the beginning ' ' and ending '\\n'\n",
    "\n",
    "        # Get the index of pairs (int)\n",
    "        pairs_index = []\n",
    "        for pair in pairs.split(', '):\n",
    "            pairs_index.append(list(map(int, pair.lstrip('(').rstrip(')').split(','))))\n",
    "\n",
    "        # Get the content of section\n",
    "        for i in range(length):\n",
    "            content[i] = f.readline().lstrip().rstrip().split(',')[3]\n",
    "\n",
    "            # Get the raw content\n",
    "            for word in content[i].split(' '):\n",
    "                refined_content[i] += word\n",
    "        \n",
    "        # For each pair\n",
    "        for pair in pairs_index:\n",
    "            dis = pair[1] - pair[0]  # Calculate dis = cause - emotion\n",
    "\n",
    "            if abs(dis) >= 5:\n",
    "                print(section)\n",
    "            \n",
    "            # Emotion clause\n",
    "            emo_conn_flag = 0  # Set no conn as default\n",
    "            emo_conn = ''\n",
    "            \n",
    "            for i in range(min(len(refined_content[pair[1] - 1]), 5)):  # Single-character word\n",
    "                if refined_content[pair[1] - 1][i] in conn_words:\n",
    "                    emo_conn_flag = 1\n",
    "                    emo_conn = refined_content[pair[1] - 1][i]\n",
    "            \n",
    "            for i in range(min(len(refined_content[pair[1] - 1]) - 1, 5)):  # Double-character word\n",
    "                if refined_content[pair[1] - 1][i:i+2] in conn_words:\n",
    "                    emo_conn_flag = 1\n",
    "                    emo_conn = refined_content[pair[1] - 1][i:i+2]\n",
    "            \n",
    "            # Cause clause\n",
    "            cau_conn_flag = 0  # Set no conn as default\n",
    "            cau_conn = ''\n",
    "\n",
    "            for i in range(min(len(refined_content[pair[0] - 1]), 5)):  # Single-character word\n",
    "                if refined_content[pair[0] - 1][i] in conn_words:\n",
    "                    cau_conn_flag = 1\n",
    "                    cau_conn = refined_content[pair[0] - 1][i]\n",
    "            \n",
    "            for i in range(min(len(refined_content[pair[0] - 1]) - 1, 5)):  # Double-character word\n",
    "                if refined_content[pair[0] - 1][i:i+2] in conn_words:\n",
    "                    cau_conn_flag = 1\n",
    "                    cau_conn = refined_content[pair[0] - 1][i:i+2]\n",
    "\n",
    "            # Judge structure type\n",
    "            # type0 (emo, cau), type1 (emo, conn, cau), type2 (conn, emo, cau), type3 (conn, emo, conn, cau)\n",
    "            # We always rewrite the sentence to make sure emo is ahead of cau for our research\n",
    "            typ = 0\n",
    "            if cau_conn_flag == 1:\n",
    "                typ = 1\n",
    "            if emo_conn_flag == 1:\n",
    "                typ = 2\n",
    "            if cau_conn_flag == 1 & emo_conn_flag == 1:\n",
    "                typ = 3\n",
    "\n",
    "            # Get statistics\n",
    "            pair_key = emo_conn + cau_conn + str(typ) + str(dis)  # Set unique key\n",
    "\n",
    "            if dis not in key:\n",
    "                if abs(dis) <= 2:\n",
    "                    key.append(dis)\n",
    "                    new_situation = Statistics(pair_key, emo_conn, cau_conn, typ, dis)\n",
    "                    result.append(new_situation)\n",
    "                else:\n",
    "                    dis = '>2'\n",
    "\n",
    "            result[key.index(dis)].frequency += 1\n",
    "\n",
    "        sec = f.readline()  # Read following section length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytransformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
